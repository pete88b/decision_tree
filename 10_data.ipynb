{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data\n",
    "\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> Functions for pre-processing data frames before feeding them into a decision tree etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decision_tree.imports import *\n",
    "from decision_tree.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe pre-processing functions\n",
    "\n",
    "This is all \"borrowed\" from https://github.com/fastai/fastai/blob/master/old/fastai/structured.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_dateparts(df, col):\n",
    "    \"\"\"converts a column of df from a datetime64 to many columns containing\n",
    "    the information from the date - inplace.\"\"\"\n",
    "    targ_pre = re.sub('[Dd]ate$', '', col.name)\n",
    "    attrs = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "             'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start',\n",
    "             'Is_year_end', 'Is_year_start']\n",
    "    for attr in attrs: df[targ_pre + attr] = getattr(col.dt, attr.lower())\n",
    "    df[targ_pre + 'Elapsed'] = col.astype(np.int64) // 10 ** 9\n",
    "    df.drop(col.name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fix_missing(df, col, na_dict):\n",
    "    \"\"\" Fill missing data in a column of df with the median, and add a {name}_na column\n",
    "    which specifies if the data was missing.\"\"\"\n",
    "    name = col.name\n",
    "    if pd.isnull(col).sum() or (name in na_dict):\n",
    "        df[name + '_na'] = pd.isnull(col)\n",
    "        na_dict[name] = na_dict[name] if name in na_dict else col.median()\n",
    "        df[name] = col.fillna(na_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def numericalize(df, col):\n",
    "    \"\"\"Changes col from date/string categorical type to its integer codes + 1.\"\"\"\n",
    "    df[col.name] = pd.Categorical(col).codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def proc_df(df, y_name, na_dict=None):\n",
    "    \"\"\"y_name name of the column that holds the dependent variable \"\"\"\n",
    "    df = df.infer_objects() # make a copy and convert cols of object type to more specific types\n",
    "    if not is_numeric_dtype(df[y_name]): df[y_name] = pd.Categorical(df[y_name]).codes\n",
    "    y = df[y_name]\n",
    "    df.drop([y_name], axis=1, inplace=True)\n",
    "    na_dict = {} if na_dict is None else na_dict.copy()\n",
    "    for _, col in df.items():\n",
    "        if pd.isnull(col).all() and col.name not in na_dict:\n",
    "            print(f'WARNING: all values for {col.name} are null. Column will be dropped')\n",
    "            df.drop(col.name, axis=1, inplace=True)\n",
    "        elif is_numeric_dtype(col): fix_missing(df, col, na_dict)\n",
    "        elif np.issubdtype(col.dtype, np.datetime64): add_dateparts(df, col)\n",
    "        else: numericalize(df, col)\n",
    "    return df, y, na_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1 col2   col3date  col4  col5\n",
      "0     1    a 2000-12-14   1.1   NaN\n",
      "1     2    b 2000-12-15   NaN   NaN\n",
      "2     3    a 2000-12-16   NaN   NaN\n",
      "WARNING: all values for col5 are null. Column will be dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   col2  col4  col3Year  col3Month  col3Week  col3Day  col3Dayofweek  \\\n",
       " 0     1   1.1      2000         12        50       14              3   \n",
       " 1     2   1.1      2000         12        50       15              4   \n",
       " 2     1   1.1      2000         12        50       16              5   \n",
       " \n",
       "    col3Dayofyear  col3Is_month_end  col3Is_month_start  col3Is_quarter_end  \\\n",
       " 0            349             False               False               False   \n",
       " 1            350             False               False               False   \n",
       " 2            351             False               False               False   \n",
       " \n",
       "    col3Is_quarter_start  col3Is_year_end  col3Is_year_start  col3Elapsed  \\\n",
       " 0                 False            False              False    976752000   \n",
       " 1                 False            False              False    976838400   \n",
       " 2                 False            False              False    976924800   \n",
       " \n",
       "    col4_na  \n",
       " 0    False  \n",
       " 1     True  \n",
       " 2     True  ,\n",
       " 0    1\n",
       " 1    2\n",
       " 2    3\n",
       " Name: col1, dtype: int64,\n",
       " {'col4': 1.1})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: xxx write proper test\n",
    "dates = pd.date_range('2000-12-14', periods=3, freq='D')\n",
    "df = pd.DataFrame({'col1':[1,2,3], 'col2':['a','b','a'], 'col3date': dates, 'col4':[1.1,np.nan,None], 'col5':[None,np.nan,None]})\n",
    "# for i in [1,4]: df[f'col{i}'] = pd.to_numeric(df[f'col{i}'])\n",
    "print(df)\n",
    "test_x, test_y, test_na_dict = proc_df(df, 'col1')\n",
    "test_x, test_y, test_na_dict\n",
    "# proced_df, y, na_dict = proc_df(df, 'col1')\n",
    "# proc_df(df, 'col2', na_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataWrapper():\n",
    "    \"Wraps the data that could be used for training trees or making predictions\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_pandas(cls, x, y):\n",
    "        \"x:dataframe, y:series\" # TODO:  support more input types\n",
    "        return DataWrapper(x.to_numpy(copy=True), y.to_numpy(copy=True), x.columns.to_numpy(copy=True), y.name)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_wrapper(cls, data, sample_idxs):\n",
    "        return DataWrapper(data.x[sample_idxs], data.y[sample_idxs], data.x_names, data.y_name)\n",
    "\n",
    "    def __init__(self, x, y, x_names, y_name=None):\n",
    "        self.x, self.y, self.x_names, self.y_name = x, y, x_names, y_name if y_name else 'y'\n",
    "        self.x_rows, self.x_cols = self.x.shape\n",
    "        self.all_x_col_idxs = np.arange(self.x_cols)\n",
    "        self.all_x_row_idxs = np.arange(self.x_rows)\n",
    "        # TODO: check that x and y can work together - same length etc\n",
    "\n",
    "    def get_sample(self, sample_idxs, col_idx=None):\n",
    "        \"sample_idxs: int for single row, array of ints for multiple rows\"\n",
    "        if col_idx is None: return self.x[sample_idxs], self.y[sample_idxs]\n",
    "        return self.x[sample_idxs, col_idx], self.y[sample_idxs]\n",
    "\n",
    "    def head(self, n_rows):\n",
    "        return DataWrapper.from_data_wrapper(self, slice(n_rows))\n",
    "\n",
    "    def tail(self, n_rows):\n",
    "        # TODO: raise error if n_rows > x_rows\n",
    "        return DataWrapper.from_data_wrapper(self, slice(self.x_rows-n_rows, self.x_rows))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'DataWrapper(x:{self.x_names} y:{self.y_name}, len:{len(self.x)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DataWrapper.from_pandas(test_x, test_y)\n",
    "assert np.array_equal([0,1,2], test_data.all_x_row_idxs)\n",
    "assert np.array_equal([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], test_data.all_x_col_idxs)\n",
    "assert np.array_equal(([2, 1], [2, 3]), test_data.get_sample([1,2], 0))\n",
    "# pass array into sample_idxs to get 2d array back - i.e. multiple rows of data\n",
    "assert test_data.x.shape == test_data.get_sample([0,1,2], None)[0].shape\n",
    "# pass an into into sample_idxs to get a 1d array back - i.e. one row of data\n",
    "assert test_data.x.shape[1] == test_data.get_sample(1, None)[0].shape[0]\n",
    "assert test_data.x_rows == 3\n",
    "test_head = test_data.head(2)\n",
    "assert test_head.x_rows == 2\n",
    "test_tail = test_data.tail(2)\n",
    "assert test_tail.x_rows == 2\n",
    "test_data = DataWrapper.from_data_wrapper(test_data, [0,2])\n",
    "assert test_data.x_rows == 2\n",
    "assert np.array_equal([0,1], test_data.all_x_row_idxs)\n",
    "assert np.array_equal(([1, 1], [1, 3]), test_data.get_sample([0,1], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "class TestClassThatDoesNothing():\n",
    "    \"\"\n",
    "    def __init__(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_target_module.ipynb.\n",
      "Converted 001_exports_to_target_module.ipynb.\n",
      "Converted 002_target_module.ipynb.\n",
      "Converted 00_core.ipynb.\n",
      "Converted 10_data.ipynb.\n",
      "Converted 20_models.ipynb.\n",
      "Converted 21_models-extra.ipynb.\n",
      "Converted 30_test_flag.ipynb.\n",
      "Converted 40_test_export.ipynb.\n",
      "Converted 50_test_doc.ipynb.\n",
      "Converted 51_test_show_doc.ipynb.\n",
      "Converted 60_all_test.ipynb.\n",
      "Converted 61_test_add2__all__.ipynb.\n",
      "Converted 70_multi_all_test_flag.ipynb.\n",
      "Converted 71_tensor_patch.ipynb.\n",
      "Converted 72_if__name__.ipynb.\n",
      "Converted 73_in_ipython.ipynb.\n",
      "Converted 80_test_coverage.ipynb.\n",
      "Converted 81_test_coverage.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
