{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Tree ensemble and decision tree models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decision_tree.imports import *\n",
    "from decision_tree.core import *\n",
    "from decision_tree.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Node():\n",
    "    def __init__(self, depth, pred, sample_idxs, split_score=np.inf):\n",
    "        self.depth, self.pred, self.sample_idxs, self.split_score = \\\n",
    "            depth, pred, sample_idxs, split_score\n",
    "        \n",
    "    def __repr__(self):\n",
    "        res = f'Node({self.depth}, {r3(self.pred)}, {self.sample_idxs}'\n",
    "        if self.split_score != np.inf: \n",
    "            res += f', {r3(self.split_score)}, {self.split_col_idx}, {r3(self.split_values)}, {self.split_idxs}, {r3(self.split_preds)}'\n",
    "        return res + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.inf == Node(1, 0.9, [1,2,3]).split_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def best_split_for_col(data, node, col_idx, min_leaf_samples=None):\n",
    "    \"Returns the best split that can be made for this column/node\"\n",
    "    _min_leaf = min_leaf_samples if min_leaf_samples else 1\n",
    "    x, y = data.get_sample(node.sample_idxs, col_idx)\n",
    "    sort_idx = np.argsort(x)\n",
    "    x, y = x[sort_idx], y[sort_idx]\n",
    "    aggs = Aggs(y)\n",
    "    stop = len(x) - _min_leaf\n",
    "    for i in range(stop):\n",
    "        aggs.upd(y[i])\n",
    "        if x[i] == x[i+1] or i < _min_leaf-1: continue\n",
    "        score = aggs.score()\n",
    "        if score < node.split_score: \n",
    "            node.split_score, node.split_col_idx = score, col_idx\n",
    "            node.split_values = x[i], x[i+1]\n",
    "            node.split_idxs = split_array(node.sample_idxs[sort_idx], i+1)\n",
    "            node.split_preds = tuple(arr.mean() for arr in split_array(y, i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataWrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4c94206e40a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m      [ 2. , -2. ]])#6\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataWrapper' is not defined"
     ]
    }
   ],
   "source": [
    "test_x = np.array(\n",
    "    [[23.2, 44.4], #0\n",
    "     [ 2. ,  2. ], #1\n",
    "     [34.3, 77.3], #2\n",
    "     [-1.5, -0.5], #3\n",
    "     [ 1.5,  1.5], #4\n",
    "     [ 1.5,  9.2], #5\n",
    "     [ 2. , -2. ]])#6\n",
    "test_y = np.array([0.0, 1.1, 2.2, 3.3, 4.4, 5.5, 6.6])\n",
    "test_data = DataWrapper.from_pandas(pd.DataFrame(test_x), pd.Series(test_y))\n",
    "\n",
    "test_node = Node(0, 0, np.arange(7))\n",
    "best_split_for_col(test_data, test_node, 0, 3)\n",
    "le_split, gt_split = test_node.split_idxs\n",
    "assert np.array_equal(test_y[le_split], [3.3, 4.4, 5.5])\n",
    "assert np.array_equal(test_y[gt_split], [1.1, 6.6, 0. , 2.2])\n",
    "\n",
    "test_node = Node(0, 0, np.arange(7))\n",
    "best_split_for_col(test_data, test_node, 1)\n",
    "le_split, gt_split = test_node.split_idxs\n",
    "assert np.array_equal(test_y[le_split], [6.6])\n",
    "assert np.array_equal(test_y[gt_split], [3.3, 4.4, 1.1, 5.5, 0. , 2.2])\n",
    "\n",
    "# not enough data to split with at least 4 values in each leaf\n",
    "test_node = Node(0, 0, np.arange(7))\n",
    "best_split_for_col(test_data, test_node, 1, 4)\n",
    "assert test_node.split_score == np.inf\n",
    "\n",
    "test_node = Node(0, 0, np.arange(7)[4:])\n",
    "test_split = best_split_for_col(test_data, test_node, 0, 1)\n",
    "le_split, gt_split = test_node.split_idxs\n",
    "assert np.array_equal(test_y[le_split], [4.4, 5.5])\n",
    "assert np.array_equal(test_y[gt_split], [6.6])\n",
    "assert test_node.split_values == (1.5, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def best_split(data, node, col_idxs, min_leaf_samples=None):\n",
    "    for col_idx in col_idxs: best_split_for_col(data, node, col_idx, min_leaf_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_node = Node(0, 0, np.arange(7))\n",
    "best_split(test_data, test_node, [0,1]); test_split\n",
    "assert test_node.split_col_idx == 1\n",
    "assert test_node.split_preds == (6.6, 2.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DecisionTree():\n",
    "    def __init__(self, data, max_depth=None, min_leaf_samples=3, col_idxs_fn=None):\n",
    "        self.data, self.max_depth, self.min_leaf_samples, self.col_idxs_fn = \\\n",
    "            data, max_depth, min_leaf_samples, col_idxs_fn\n",
    "    \n",
    "    def _col_idxs(self):\n",
    "        return self.col_idxs_fn(self.data.all_x_col_idxs) if self.col_idxs_fn else self.data.all_x_col_idxs\n",
    "    \n",
    "    def _recursive_split(self, node):\n",
    "        best_split(self.data, node, self._col_idxs(), self.min_leaf_samples)\n",
    "        if node.split_score == np.inf: return\n",
    "        for op, value, idxs, pred in zip(['le', 'gt'], node.split_values, node.split_idxs, node.split_preds):\n",
    "            setattr(node, op, Node(node.depth+1, pred, idxs))\n",
    "            self._recursive_split(getattr(node, op))\n",
    "        \n",
    "    def fit(self):\n",
    "        self.node = Node(1, self.data.y.mean(), self.data.all_x_row_idxs)\n",
    "        self._recursive_split(self.node)\n",
    "        return self\n",
    "    \n",
    "    def predict_row(self, row):\n",
    "        return predict_row(row, self.node)\n",
    "    \n",
    "    def predict(self, rows): \n",
    "        return np.array([self.predict_row(rows[i]) for i in range(len(rows))])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'dTree(data={self.data} max_depth={self.max_depth} min_leaf_samples={self.min_leaf_samples})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_tree(tree):\n",
    "    \"print tree with splits, depth first\"\n",
    "    print(tree)\n",
    "    print('col_idxs_fn', tree.col_idxs_fn if tree.col_idxs_fn else 'default')\n",
    "    if not hasattr(tree, 'node'): return\n",
    "    queue = [tree.node]\n",
    "    while len(queue) != 0:\n",
    "        node = queue.pop(0)\n",
    "        print(node)\n",
    "        for k in ['le', 'gt']:\n",
    "            if getattr(node, k, False): queue.append(getattr(node, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_y)\n",
    "print_tree(DecisionTree(test_data, min_leaf_samples=2).fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(DecisionTree(test_data, min_leaf_samples=1).fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: xxxx clean-up\n",
    "\n",
    "Might we be able to generalize better by ;\n",
    "- adding a little randomness by using a split value that lies somewhere between the lower and upper boundary of the split. See np.random.uniform ...\n",
    "- use the average of the lower and upper boundary values\n",
    "\n",
    "both of these could be done at prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def predict_row(row, node):\n",
    "    \"make a prediction for the specified row, using the specified node\"\n",
    "    if node.split_score == np.inf: return node.pred\n",
    "    split_value = node.split_values[0] # TODO: use just lower value for now\n",
    "    split_col_idx = node.split_col_idx\n",
    "    row_value = row[split_col_idx]\n",
    "    next_node = node.le if row_value<=split_value else node.gt\n",
    "    return predict_row(row, next_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we make a prediction for a row that was used in training and we have only 1 sample in each leaf, the tree should predict exactly the right answer\n",
    "- grab a single row of data\n",
    "- make a prediction for this row\n",
    "- assert that the prediction we made matches the actual for this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = DecisionTree(test_data, min_leaf_samples=1).fit()\n",
    "for i in range(test_data.x_rows):\n",
    "    test_sample = test_data.get_sample(i)\n",
    "    assert predict_row(test_sample[0], test_tree.node) == test_sample[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up some data for testing. This data is copied from the final model used in https://github.com/fastai/fastai/tree/master/courses/ml1/lesson2-rf_interpretation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulldozers_data = np.load('test/data/bulldozers.npy', allow_pickle=True)\n",
    "train_data = DataWrapper(*bulldozers_data[:4])\n",
    "valid_data = DataWrapper(*bulldozers_data[4:])\n",
    "train_data, valid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a very small amount of data to train a decision tree, then print the root node so we can see how the data has been split.\n",
    "\n",
    "It's interesting that the depth of this tree is greater than the expected `np.log2(test_tree.data.x_rows)` - because it's unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = DecisionTree(train_data.tail(10), min_leaf_samples=1).fit()\n",
    "print_tree(test_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for all of the data we trained on. \n",
    "\n",
    "Although we set `min_leaf_samples=1`, not every sample has it's own leaf. If 2 or more samples have;\n",
    "- the same values for all independent variables and\n",
    "- different values for the dependent variable,\n",
    "- they will end up in the same leaf (because we can't find a value to split on) that will predict the mean of the dependent variables for all samples in the leaf\n",
    "\n",
    "So we expect preds to be nearly 100% correct;\n",
    "- loss to be nearly zero\n",
    "- predictions vs actual plots a strait line with just a little variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = DecisionTree(train_data.tail(2000), min_leaf_samples=1).fit()\n",
    "test_preds = test_tree.predict(test_tree.data.x)\n",
    "loss = rmse(test_preds, test_tree.data.y); print('loss', loss)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(test_preds, test_tree.data.y, alpha=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for all of the data we trained on again - but allow a minimum of 5 items in each leaf. So we see;\n",
    "- a non-zero loss\n",
    "- some variance in the predictions vs actual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = DecisionTree(train_data.tail(2000), min_leaf_samples=5).fit()\n",
    "test_preds = test_tree.predict(test_tree.data.x)\n",
    "loss = rmse(test_preds, test_tree.data.y); print('loss', loss)\n",
    "plt.scatter(test_preds, test_tree.data.y, alpha=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the validation data - we don't expect a single tree to be very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_tree.predict(valid_data.x)\n",
    "loss = rmse(test_preds, valid_data.y); print('loss', loss)\n",
    "plt.scatter(test_preds, valid_data.y, alpha=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Ensemble (AKA Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TreeEnsemble():\n",
    "    def __init__(self, data, sample_size, max_depth=None, min_leaf_samples=3, n_trees=10, col_idxs_fn=None):\n",
    "        self.data, self.sample_size, self.max_depth, self.min_leaf_samples, self.n_trees = \\\n",
    "                data, sample_size, max_depth, min_leaf_samples, n_trees\n",
    "        if col_idxs_fn is None:\n",
    "            n_cols = int(data.x_cols*0.5)\n",
    "            self.col_idxs_fn = partial(np.random.choice, size=n_cols, replace=False)\n",
    "        self.trees = []\n",
    "        for i in range(n_trees):\n",
    "            sample_idxs = np.random.permutation(data.x_rows)[:sample_size]\n",
    "            sample_data = DataWrapper.from_data_wrapper(data, sample_idxs)\n",
    "            self.trees.append(DecisionTree(sample_data, max_depth, min_leaf_samples, col_idxs_fn))\n",
    "    \n",
    "    def fit(self, max_workers=12):\n",
    "        if max_workers == 0:\n",
    "            [t.fit() for t in self.trees]\n",
    "        else:\n",
    "            with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "                self.trees = list(executor.map(DecisionTree.fit, self.trees))\n",
    "        return self\n",
    "    \n",
    "    def predict_row(self, row):\n",
    "        return np.array([t.predict_row(row) for t in self.trees]).mean()\n",
    "    \n",
    "    def predict(self, rows): \n",
    "        return np.array([self.predict_row(rows[i]) for i in range(len(rows))])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'tEnsemble(data={self.data} n_trees={self.n_trees} sample_size={self.sample_size} max_depth={self.max_depth} min_leaf_samples={self.min_leaf_samples})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tree ensemble and check that it has initialized correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble = TreeEnsemble(train_data.tail(2000), sample_size=750, min_leaf_samples=5)\n",
    "assert test_ensemble.sample_size == 750 == test_ensemble.trees[0].data.x_rows == len(test_ensemble.trees[0].data.y)\n",
    "assert len(test_ensemble.col_idxs_fn(test_ensemble.data.all_x_col_idxs)) == 9\n",
    "assert len(test_ensemble.trees) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the ensemble and get predictions for all of the data we trained on - TODO: I'd expect this to be better than a single tree but the loss is the same. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble.fit()\n",
    "test_preds = test_ensemble.predict(test_ensemble.data.x)\n",
    "loss = rmse(test_preds, test_ensemble.data.y); print('loss', loss)\n",
    "plt.scatter(test_preds, test_ensemble.data.y, alpha=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the validation data - expect this to be better than a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_ensemble.predict(valid_data.x)\n",
    "loss = rmse(test_preds, valid_data.y); print('loss', loss)\n",
    "plt.scatter(test_preds, valid_data.y, alpha=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "\n",
    "- add classification capability\n",
    "\n",
    "\n",
    "- confidence based on tree pred variance\n",
    "- feature importance\n",
    "    - jumble single column -> create preds - which column makes preds the worst when jumbled\n",
    "    - WHAT are you forgetting?\n",
    "        - is it which split/feature contributes the biggest change from \"bias\" to \"pred\"\n",
    "    - avg depth of feature in tree <- i just made this up\n",
    "- show dendogram of rank correlation\n",
    "- partial dependence\n",
    "    - ggplot if monotonic relationship\n",
    "    - do the \"what if\" preds - i.e. change year of sale to 1960 and see what things would have sold for\n",
    "    - pdp plot\n",
    "- tree interpret\n",
    "    - for single row pred: print contribution of each split (feature) to final result\n",
    "    - waterfall chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
