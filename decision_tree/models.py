# AUTOGENERATED! DO NOT EDIT! File to edit: 20_models.ipynb (unless otherwise specified).

__all__ = ['Node', 'best_split_for_col', 'best_split', 'DecisionTree', 'print_tree', 'predict_row', 'TreeEnsemble']

# Cell
from .imports import *
from .core import *
from .data import *

# Cell
class Node():
    def __init__(self, depth, pred, sample_idxs, split_score=np.inf):
        self.depth, self.pred, self.sample_idxs, self.split_score = \
            depth, pred, sample_idxs, split_score

    def __repr__(self):
        res = f'Node({self.depth}, {r3(self.pred)}, {self.sample_idxs}'
        if self.split_score != np.inf:
            res += f', {r3(self.split_score)}, {self.split_col_idx}, {r3(self.split_values)}, {self.split_idxs}, {r3(self.split_preds)}'
        return res + ')'

# Cell
def best_split_for_col(data, node, col_idx, min_leaf_samples=None):
    "Returns the best split that can be made for this column/node"
    _min_leaf = min_leaf_samples if min_leaf_samples else 1
    x, y = data.get_sample(node.sample_idxs, col_idx)
    sort_idx = np.argsort(x)
    x, y = x[sort_idx], y[sort_idx]
    aggs = Aggs(y)
    stop = len(x) - _min_leaf
    for i in range(stop):
        aggs.upd(y[i])
        if x[i] == x[i+1] or i < _min_leaf-1: continue
        score = aggs.score()
        if score < node.split_score:
            node.split_score, node.split_col_idx = score, col_idx
            node.split_values = x[i], x[i+1]
            node.split_idxs = split_array(node.sample_idxs[sort_idx], i+1)
            node.split_preds = tuple(arr.mean() for arr in split_array(y, i+1))

# Cell
def best_split(data, node, col_idxs, min_leaf_samples=None):
    for col_idx in col_idxs: best_split_for_col(data, node, col_idx, min_leaf_samples)

# Cell
class DecisionTree():
    def __init__(self, data, max_depth=None, min_leaf_samples=3, col_idxs_fn=None):
        self.data, self.max_depth, self.min_leaf_samples, self.col_idxs_fn = \
            data, max_depth, min_leaf_samples, col_idxs_fn

    def _col_idxs(self):
        return self.col_idxs_fn(self.data.all_x_col_idxs) if self.col_idxs_fn else self.data.all_x_col_idxs

    def _recursive_split(self, node):
        best_split(self.data, node, self._col_idxs(), self.min_leaf_samples)
        if node.split_score == np.inf: return
        for op, value, idxs, pred in zip(['le', 'gt'], node.split_values, node.split_idxs, node.split_preds):
            setattr(node, op, Node(node.depth+1, pred, idxs))
            self._recursive_split(getattr(node, op))

    def fit(self):
        self.node = Node(1, self.data.y.mean(), self.data.all_x_row_idxs)
        self._recursive_split(self.node)
        return self

    def predict_row(self, row):
        return predict_row(row, self.node)

    def predict(self, rows):
        return np.array([self.predict_row(rows[i]) for i in range(len(rows))])

    def __repr__(self):
        return f'dTree(data={self.data} max_depth={self.max_depth} min_leaf_samples={self.min_leaf_samples})'

# Cell
def print_tree(tree):
    "print tree with splits, depth first"
    print(tree)
    print('col_idxs_fn', tree.col_idxs_fn if tree.col_idxs_fn else 'default')
    if not hasattr(tree, 'node'): return
    queue = [tree.node]
    while len(queue) != 0:
        node = queue.pop(0)
        print(node)
        for k in ['le', 'gt']:
            if getattr(node, k, False): queue.append(getattr(node, k))

# Cell
def predict_row(row, node):
    "make a prediction for the specified row, using the specified node"
    if node.split_score == np.inf: return node.pred
    split_value = node.split_values[0] # TODO: use just lower value for now
    split_col_idx = node.split_col_idx
    row_value = row[split_col_idx]
    next_node = node.le if row_value<=split_value else node.gt
    return predict_row(row, next_node)

# Cell
class TreeEnsemble():
    def __init__(self, data, sample_size, max_depth=None, min_leaf_samples=3, n_trees=10, col_idxs_fn=None):
        self.data, self.sample_size, self.max_depth, self.min_leaf_samples, self.n_trees = \
                data, sample_size, max_depth, min_leaf_samples, n_trees
        if col_idxs_fn is None:
            n_cols = int(data.x_cols*0.5)
            self.col_idxs_fn = partial(np.random.choice, size=n_cols, replace=False)
        self.trees = []
        for i in range(n_trees):
            sample_idxs = np.random.permutation(data.x_rows)[:sample_size]
            sample_data = DataWrapper.from_data_wrapper(data, sample_idxs)
            self.trees.append(DecisionTree(sample_data, max_depth, min_leaf_samples, col_idxs_fn))

    def fit(self, max_workers=12):
        if max_workers == 0:
            [t.fit() for t in self.trees]
        else:
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                self.trees = list(executor.map(DecisionTree.fit, self.trees))
        return self

    def predict_row(self, row):
        return np.array([t.predict_row(row) for t in self.trees]).mean()

    def predict(self, rows):
        return np.array([self.predict_row(rows[i]) for i in range(len(rows))])

    def __repr__(self):
        return f'tEnsemble(data={self.data} n_trees={self.n_trees} sample_size={self.sample_size} max_depth={self.max_depth} min_leaf_samples={self.min_leaf_samples})'